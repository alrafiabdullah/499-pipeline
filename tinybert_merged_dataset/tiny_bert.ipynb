{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from simpletransformers.language_modeling import LanguageModelingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12050MB, multi_processor_count=28)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training TinyBERT model with merged datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LOC = \"/home/abdullah/Code/dl/lt_bert/dataset/texts/merged_train.txt\"\n",
    "TEST_LOC = \"/home/abdullah/Code/dl/lt_bert/dataset/texts/merged_test.txt\"\n",
    "\n",
    "SOCIAL_LOC = \"/home/abdullah/Code/dl/lt_bert/dataset/texts/social_train.txt\"\n",
    "SADHU_LOC = \"/home/abdullah/Code/dl/lt_bert/dataset/texts/sadhu_train.txt\"\n",
    "ASR_LOC = \"/home/abdullah/Code/dl/lt_bert/dataset/texts/asr_train.txt\"\n",
    "PROTHOMALO_LOC = \"/home/abdullah/Code/dl/lt_bert/dataset/texts/prothomalo_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 247181/247181 [00:09<00:00, 25557.01it/s]\n",
      "100%|██████████| 55959/55959 [00:00<00:00, 180789.49it/s]\n",
      "Epochs 0/100. Running Loss:    2.8662: 100%|██████████| 2332/2332 [01:14<00:00, 31.12it/s]\n",
      "Epochs 1/100. Running Loss:    2.6973: 100%|██████████| 2332/2332 [01:14<00:00, 31.43it/s]\n",
      "Epochs 2/100. Running Loss:    2.3944: 100%|██████████| 2332/2332 [01:13<00:00, 31.57it/s]\n",
      "Epochs 3/100. Running Loss:    2.5464: 100%|██████████| 2332/2332 [01:15<00:00, 30.91it/s]\n",
      "Epochs 4/100. Running Loss:    2.5861: 100%|██████████| 2332/2332 [01:15<00:00, 30.78it/s]\n",
      "Epochs 5/100. Running Loss:    2.2398: 100%|██████████| 2332/2332 [01:16<00:00, 30.66it/s]\n",
      "Epochs 6/100. Running Loss:    2.1951: 100%|██████████| 2332/2332 [01:16<00:00, 30.56it/s]\n",
      "Epochs 7/100. Running Loss:    2.3362: 100%|██████████| 2332/2332 [01:15<00:00, 31.08it/s]\n",
      "Epochs 8/100. Running Loss:    2.2102: 100%|██████████| 2332/2332 [01:14<00:00, 31.18it/s]\n",
      "Epochs 9/100. Running Loss:    2.1708: 100%|██████████| 2332/2332 [01:15<00:00, 30.94it/s]\n",
      "Epochs 10/100. Running Loss:    2.1904: 100%|██████████| 2332/2332 [01:15<00:00, 30.94it/s]\n",
      "Epochs 11/100. Running Loss:    2.0428: 100%|██████████| 2332/2332 [01:15<00:00, 31.09it/s]\n",
      "Epochs 12/100. Running Loss:    2.2184: 100%|██████████| 2332/2332 [01:16<00:00, 30.67it/s]\n",
      "Epochs 13/100. Running Loss:    2.1114: 100%|██████████| 2332/2332 [01:15<00:00, 30.86it/s]\n",
      "Epochs 14/100. Running Loss:    2.0151: 100%|██████████| 2332/2332 [01:16<00:00, 30.42it/s]\n",
      "Epochs 15/100. Running Loss:    1.9802: 100%|██████████| 2332/2332 [01:16<00:00, 30.63it/s]\n",
      "Epochs 16/100. Running Loss:    2.2456: 100%|██████████| 2332/2332 [01:16<00:00, 30.59it/s]\n",
      "Epochs 17/100. Running Loss:    2.0922: 100%|██████████| 2332/2332 [01:19<00:00, 29.40it/s]\n",
      "Epochs 18/100. Running Loss:    2.0061: 100%|██████████| 2332/2332 [01:17<00:00, 30.23it/s]\n",
      "Epochs 19/100. Running Loss:    2.1242: 100%|██████████| 2332/2332 [01:18<00:00, 29.87it/s]\n",
      "Epochs 20/100. Running Loss:    2.1122: 100%|██████████| 2332/2332 [01:17<00:00, 29.95it/s]\n",
      "Epochs 21/100. Running Loss:    2.1136: 100%|██████████| 2332/2332 [01:17<00:00, 29.94it/s]\n",
      "Epochs 22/100. Running Loss:    1.9539: 100%|██████████| 2332/2332 [01:13<00:00, 31.63it/s]\n",
      "Epochs 23/100. Running Loss:    1.6701: 100%|██████████| 2332/2332 [01:14<00:00, 31.36it/s]\n",
      "Epochs 24/100. Running Loss:    2.3040: 100%|██████████| 2332/2332 [01:16<00:00, 30.58it/s]\n",
      "Epochs 25/100. Running Loss:    2.0294: 100%|██████████| 2332/2332 [01:17<00:00, 30.11it/s]\n",
      "Epochs 26/100. Running Loss:    1.8383: 100%|██████████| 2332/2332 [01:17<00:00, 30.00it/s]\n",
      "Epochs 27/100. Running Loss:    2.0335: 100%|██████████| 2332/2332 [01:16<00:00, 30.48it/s]\n",
      "Epochs 28/100. Running Loss:    1.9898: 100%|██████████| 2332/2332 [01:14<00:00, 31.34it/s]\n",
      "Epochs 29/100. Running Loss:    2.0929: 100%|██████████| 2332/2332 [01:15<00:00, 30.97it/s]\n",
      "Epochs 30/100. Running Loss:    1.7693: 100%|██████████| 2332/2332 [01:15<00:00, 31.01it/s]\n",
      "Epochs 31/100. Running Loss:    1.9642: 100%|██████████| 2332/2332 [01:15<00:00, 31.05it/s]\n",
      "Epochs 32/100. Running Loss:    1.9332: 100%|██████████| 2332/2332 [01:13<00:00, 31.62it/s]\n",
      "Epochs 33/100. Running Loss:    1.9218: 100%|██████████| 2332/2332 [01:12<00:00, 32.15it/s]\n",
      "Epochs 34/100. Running Loss:    2.0030: 100%|██████████| 2332/2332 [01:12<00:00, 32.34it/s]\n",
      "Epochs 35/100. Running Loss:    1.7730: 100%|██████████| 2332/2332 [01:11<00:00, 32.81it/s]\n",
      "Epochs 36/100. Running Loss:    1.7355: 100%|██████████| 2332/2332 [01:14<00:00, 31.39it/s]\n",
      "Epochs 37/100. Running Loss:    1.8115: 100%|██████████| 2332/2332 [01:15<00:00, 30.99it/s]\n",
      "Epochs 38/100. Running Loss:    2.0575: 100%|██████████| 2332/2332 [01:11<00:00, 32.71it/s]\n",
      "Epochs 39/100. Running Loss:    1.8638: 100%|██████████| 2332/2332 [01:10<00:00, 33.11it/s]\n",
      "Epochs 40/100. Running Loss:    2.0352: 100%|██████████| 2332/2332 [01:12<00:00, 32.39it/s]\n",
      "Epochs 41/100. Running Loss:    1.5878: 100%|██████████| 2332/2332 [01:11<00:00, 32.70it/s]\n",
      "Epochs 42/100. Running Loss:    1.9811: 100%|██████████| 2332/2332 [01:13<00:00, 31.91it/s]\n",
      "Epochs 43/100. Running Loss:    1.6297: 100%|██████████| 2332/2332 [01:10<00:00, 32.96it/s]\n",
      "Epochs 44/100. Running Loss:    1.9387: 100%|██████████| 2332/2332 [01:10<00:00, 32.85it/s]\n",
      "Epochs 45/100. Running Loss:    1.8857: 100%|██████████| 2332/2332 [01:11<00:00, 32.72it/s]\n",
      "Epochs 46/100. Running Loss:    1.6791: 100%|██████████| 2332/2332 [01:10<00:00, 33.15it/s]\n",
      "Epochs 47/100. Running Loss:    1.9709: 100%|██████████| 2332/2332 [01:11<00:00, 32.83it/s]\n",
      "Epochs 48/100. Running Loss:    1.9518: 100%|██████████| 2332/2332 [01:10<00:00, 32.87it/s]\n",
      "Epochs 49/100. Running Loss:    1.8214: 100%|██████████| 2332/2332 [01:11<00:00, 32.42it/s]\n",
      "Epochs 50/100. Running Loss:    1.7434: 100%|██████████| 2332/2332 [01:10<00:00, 33.16it/s]\n",
      "Epochs 51/100. Running Loss:    2.1630: 100%|██████████| 2332/2332 [01:10<00:00, 32.88it/s]\n",
      "Epochs 52/100. Running Loss:    1.9950: 100%|██████████| 2332/2332 [01:11<00:00, 32.56it/s]\n",
      "Epochs 53/100. Running Loss:    1.8846: 100%|██████████| 2332/2332 [01:10<00:00, 32.86it/s]\n",
      "Epochs 54/100. Running Loss:    1.9768: 100%|██████████| 2332/2332 [01:11<00:00, 32.83it/s]\n",
      "Epochs 55/100. Running Loss:    1.9456: 100%|██████████| 2332/2332 [01:11<00:00, 32.75it/s]\n",
      "Epochs 56/100. Running Loss:    1.7276: 100%|██████████| 2332/2332 [01:10<00:00, 33.06it/s]\n",
      "Epochs 57/100. Running Loss:    2.0842: 100%|██████████| 2332/2332 [01:13<00:00, 31.75it/s]\n",
      "Epochs 58/100. Running Loss:    1.8659: 100%|██████████| 2332/2332 [01:13<00:00, 31.91it/s]\n",
      "Epochs 59/100. Running Loss:    1.8812: 100%|██████████| 2332/2332 [01:16<00:00, 30.42it/s]\n",
      "Epochs 60/100. Running Loss:    1.7347: 100%|██████████| 2332/2332 [01:14<00:00, 31.26it/s]\n",
      "Epochs 61/100. Running Loss:    1.9498: 100%|██████████| 2332/2332 [01:11<00:00, 32.59it/s]\n",
      "Epochs 62/100. Running Loss:    1.8785: 100%|██████████| 2332/2332 [01:10<00:00, 33.09it/s]\n",
      "Epochs 63/100. Running Loss:    1.9249: 100%|██████████| 2332/2332 [01:08<00:00, 34.12it/s]\n",
      "Epochs 64/100. Running Loss:    1.9691: 100%|██████████| 2332/2332 [01:08<00:00, 34.25it/s]\n",
      "Epochs 65/100. Running Loss:    2.0817: 100%|██████████| 2332/2332 [01:08<00:00, 33.89it/s]\n",
      "Epochs 66/100. Running Loss:    1.7997: 100%|██████████| 2332/2332 [01:08<00:00, 33.91it/s]\n",
      "Epochs 67/100. Running Loss:    1.7397: 100%|██████████| 2332/2332 [01:08<00:00, 34.14it/s]\n",
      "Epochs 68/100. Running Loss:    1.7069: 100%|██████████| 2332/2332 [01:08<00:00, 33.96it/s]\n",
      "Epochs 69/100. Running Loss:    1.9636: 100%|██████████| 2332/2332 [01:08<00:00, 34.09it/s]\n",
      "Epochs 70/100. Running Loss:    1.9945: 100%|██████████| 2332/2332 [01:09<00:00, 33.55it/s]\n",
      "Epochs 71/100. Running Loss:    1.6271: 100%|██████████| 2332/2332 [01:08<00:00, 33.82it/s]\n",
      "Epochs 72/100. Running Loss:    1.8874: 100%|██████████| 2332/2332 [01:09<00:00, 33.75it/s]\n",
      "Epochs 73/100. Running Loss:    1.8222: 100%|██████████| 2332/2332 [01:08<00:00, 33.87it/s]\n",
      "Epochs 74/100. Running Loss:    1.9423: 100%|██████████| 2332/2332 [01:12<00:00, 32.07it/s]\n",
      "Epochs 75/100. Running Loss:    1.8950: 100%|██████████| 2332/2332 [01:12<00:00, 32.05it/s]\n",
      "Epochs 76/100. Running Loss:    1.6631: 100%|██████████| 2332/2332 [01:11<00:00, 32.40it/s]\n",
      "Epochs 77/100. Running Loss:    1.8176: 100%|██████████| 2332/2332 [01:10<00:00, 32.98it/s]\n",
      "Epochs 78/100. Running Loss:    1.5633: 100%|██████████| 2332/2332 [01:08<00:00, 33.87it/s]\n",
      "Epochs 79/100. Running Loss:    1.9197: 100%|██████████| 2332/2332 [01:08<00:00, 34.25it/s]\n",
      "Epochs 80/100. Running Loss:    2.1717: 100%|██████████| 2332/2332 [01:08<00:00, 33.99it/s]\n",
      "Epochs 81/100. Running Loss:    1.9684: 100%|██████████| 2332/2332 [01:08<00:00, 34.17it/s]\n",
      "Epochs 82/100. Running Loss:    2.0404: 100%|██████████| 2332/2332 [01:08<00:00, 34.20it/s]\n",
      "Epochs 83/100. Running Loss:    1.8416: 100%|██████████| 2332/2332 [01:08<00:00, 33.98it/s]\n",
      "Epochs 84/100. Running Loss:    1.8919: 100%|██████████| 2332/2332 [01:08<00:00, 33.99it/s]\n",
      "Epochs 85/100. Running Loss:    1.9616: 100%|██████████| 2332/2332 [01:08<00:00, 34.28it/s]\n",
      "Epochs 86/100. Running Loss:    1.8732: 100%|██████████| 2332/2332 [01:09<00:00, 33.69it/s]\n",
      "Epochs 87/100. Running Loss:    1.9259: 100%|██████████| 2332/2332 [01:08<00:00, 34.26it/s]\n",
      "Epochs 88/100. Running Loss:    1.8971: 100%|██████████| 2332/2332 [01:08<00:00, 33.88it/s]\n",
      "Epochs 89/100. Running Loss:    1.9493: 100%|██████████| 2332/2332 [01:08<00:00, 34.08it/s]\n",
      "Epochs 90/100. Running Loss:    1.7291: 100%|██████████| 2332/2332 [01:10<00:00, 33.01it/s]\n",
      "Epochs 91/100. Running Loss:    1.6778: 100%|██████████| 2332/2332 [01:09<00:00, 33.35it/s]\n",
      "Epochs 92/100. Running Loss:    1.8050: 100%|██████████| 2332/2332 [01:08<00:00, 33.85it/s]\n",
      "Epochs 93/100. Running Loss:    1.7999: 100%|██████████| 2332/2332 [01:08<00:00, 34.27it/s]\n",
      "Epochs 94/100. Running Loss:    1.7279: 100%|██████████| 2332/2332 [01:08<00:00, 34.21it/s]\n",
      "Epochs 95/100. Running Loss:    1.8183: 100%|██████████| 2332/2332 [01:08<00:00, 33.87it/s]\n",
      "Epochs 96/100. Running Loss:    1.9532: 100%|██████████| 2332/2332 [01:08<00:00, 34.03it/s]\n",
      "Epochs 97/100. Running Loss:    1.8591: 100%|██████████| 2332/2332 [01:09<00:00, 33.52it/s]\n",
      "Epochs 98/100. Running Loss:    1.8118: 100%|██████████| 2332/2332 [01:08<00:00, 33.94it/s]\n",
      "Epochs 99/100. Running Loss:    1.7276: 100%|██████████| 2332/2332 [01:08<00:00, 33.92it/s]\n",
      "Epoch 100 of 100: 100%|██████████| 100/100 [2:01:12<00:00, 72.72s/it]\n",
      "100%|██████████| 30899/30899 [00:01<00:00, 16013.27it/s]\n",
      "100%|██████████| 7043/7043 [00:00<00:00, 102181.55it/s]\n",
      "Running Evaluation: 100%|██████████| 147/147 [00:04<00:00, 36.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main {'eval_loss': 1.6111257392532972, 'perplexity': tensor(5.0084)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.38s/it]\n",
      "100%|██████████| 11697/11697 [00:00<00:00, 180245.91it/s]\n",
      "Running Evaluation: 100%|██████████| 244/244 [00:06<00:00, 38.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social {'eval_loss': 1.6029354353420069, 'perplexity': tensor(4.9676)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.50s/it]\n",
      "100%|██████████| 40433/40433 [00:00<00:00, 176409.34it/s]\n",
      "Running Evaluation: 100%|██████████| 843/843 [00:21<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadhu {'eval_loss': 1.5072933565537983, 'perplexity': tensor(4.5145)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:02<00:00, 62.43s/it]\n",
      "100%|██████████| 95848/95848 [00:00<00:00, 145952.55it/s]\n",
      "Running Evaluation: 100%|██████████| 1997/1997 [00:51<00:00, 38.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asr {'eval_loss': 2.208796659946203, 'perplexity': tensor(9.1048)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  4.00s/it]\n",
      "100%|██████████| 6282/6282 [00:00<00:00, 221791.58it/s]\n",
      "Running Evaluation: 100%|██████████| 131/131 [00:03<00:00, 39.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prothomalo {'eval_loss': 1.9341062079859144, 'perplexity': tensor(6.9179)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModelingModel('bert', 'google/bert_uncased_L-2_H-128_A-2', use_cuda=True, args={\n",
    "    \"num_train_epochs\": 100, \"overwrite_output_dir\": True, \"best_model_dir\": f\"results/best_model/\", \"train_batch_size\": 24, \"eval_batch_size\": 48}\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.train_model(\n",
    "    train_file=TRAIN_LOC, output_dir=f\"results/\")\n",
    "\n",
    "result = model.eval_model(\n",
    "    eval_file=TEST_LOC, output_dir=f\"results/eval/\")\n",
    "\n",
    "print(\"Main\", result)\n",
    "\n",
    "# Social\n",
    "result = model.eval_model(\n",
    "    eval_file=SOCIAL_LOC, output_dir=f\"results/eval/\")\n",
    "\n",
    "print(\"Social\", result)\n",
    "\n",
    "# Sadhu\n",
    "result = model.eval_model(\n",
    "    eval_file=SADHU_LOC, output_dir=f\"results/eval/\")\n",
    "\n",
    "print(\"Sadhu\", result)\n",
    "\n",
    "# asr\n",
    "result = model.eval_model(\n",
    "    eval_file=ASR_LOC, output_dir=f\"results/eval/\")\n",
    "\n",
    "print(\"Asr\", result)\n",
    "\n",
    "# prothomalo\n",
    "result = model.eval_model(\n",
    "    eval_file=PROTHOMALO_LOC, output_dir=f\"results/eval/\")\n",
    "\n",
    "print(\"Prothomalo\", result)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30945d60abeb4d30e097bab3ad7b6ead7c1fba264acb4ede644ab6174c0ba9cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv_499A': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
