{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (BertTokenizer, BertForSequenceClassification, Trainer,\n",
    "                          TrainingArguments, BertPreTrainedModel)\n",
    "# from simpletransformers.language_modeling import LanguageModelingModel\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 3060', major=8, minor=6, total_memory=12050MB, multi_processor_count=28)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '/home/abdullah/Code/dl/lt_bert/best_models/pruned_best_tiny_bert'\n",
    "TRAIN_FILE_LOC = '/home/abdullah/Code/dl/bnlp-resources/sentiment/SAIL_data/BN_data_train.tsv'\n",
    "TEST_FILE_LOC = '/home/abdullah/Code/dl/bnlp-resources/sentiment/SAIL_data/BN_data_test.tsv'\n",
    "EVAL_FILE_LOC = '/home/abdullah/Code/dl/bnlp-resources/sentiment/SAIL_data/BN_data_dev.tsv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/abdullah/Code/dl/bnlp-resources/sentiment/SAIL_data/BN_data_train.txt',\n",
       " 'BN_data_train']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tsv_to_text(tsv_file_loc):\n",
    "    file_name = tsv_file_loc.split(\"/\")[-1].split(\".\")[0]\n",
    "    txt_name = tsv_file_loc.replace(\".tsv\", \".txt\")\n",
    "    txt_name = txt_name.replace(\"split_merged\", \"texts\")\n",
    "\n",
    "    if os.path.exists(txt_name):\n",
    "        return [txt_name, file_name]\n",
    "\n",
    "    df = pd.read_csv(tsv_file_loc, sep=\"\\t\")\n",
    "\n",
    "    for txt in df[\"text\"]:\n",
    "        with open(txt_name, \"a\", encoding=\"utf8\") as f:\n",
    "            f.writelines(txt + \"\\n\")\n",
    "    return [txt_name, file_name]\n",
    "\n",
    "\n",
    "tsv_to_text(TRAIN_FILE_LOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text class\n",
      "0    'পকেটে শখানেক টাকা ... আর এই মুহুর্তে দিনব্যাপ...     2\n",
      "1    'শেষ পর্যায়ে এসে গল্পটা এভাবে ভুল পথে মোড় না...     2\n",
      "2    'সংসদেও ঘুমালেন সমাজকল্যাণ মন্ত্রী  http://t.c...     2\n",
      "3    'সীমান্তে নারী ও শিশুসহ আটক ৮ http://t.co/Fz3d...     2\n",
      "4    'আমিও মানুষ ভালা না, মনে মনে শুয়োরের বাচ্চা বল...     2\n",
      "..                                                 ...   ...\n",
      "199  'আবের সঙ্গে সৌজন্য সাক্ষাৎ করেছেন খালেদা জিয়া...     1\n",
      "200  'ভৈরব নদ সংস্কার ও খননের দাবিতে জনউদ্যোগের মান...     1\n",
      "201  'আলো টেলিফিল্মটা দেখলাম। মাঝেমধ্যে পর্যাপ্ত পর...     1\n",
      "202      '@arif_rony2 তারপরে ও দেখতে পেলে খুব মজা পাই'     1\n",
      "203  'চল কাবার পানে ওহে মুহাজির,পেতে প্রেম শুধা আল্...     1\n",
      "\n",
      "[204 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def tsv_to_df(csv_file_loc):\n",
    "    df = pd.read_csv(csv_file_loc, sep='\\t')\n",
    "    # remove id column\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "    # replace neutral with 0, positive with 1, negative with 2 in class_label column\n",
    "    df.loc[df['class'] == 'BN_NEU', 'class'] = 0\n",
    "    df.loc[df['class'] == 'BN_POS', 'class'] = 1\n",
    "    df.loc[df['class'] == 'BN_NEG', 'class'] = 2\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = tsv_to_df(TEST_FILE_LOC)\n",
    "\n",
    "texts = train_df['text'].tolist()\n",
    "print(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_calculator(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # calculate accuracy using sklearn's function\n",
    "  f1 = f1_score(labels, preds, average='weighted')\n",
    "  return {\n",
    "      'f1': f1,\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = tsv_to_text(TRAIN_FILE_LOC)\n",
    "test_list = tsv_to_text(TEST_FILE_LOC)\n",
    "eval_list = tsv_to_text(EVAL_FILE_LOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/abdullah/Code/dl/lt_bert/best_models/pruned_best_tiny_bert were not used when initializing BertForSequenceClassification: ['bert.encoder.layer.1.intermediate.dense.weight_mask', 'bert.encoder.layer.1.attention.output.dense.weight_mask', 'bert.encoder.layer.0.intermediate.dense.weight_orig', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight_mask', 'bert.encoder.layer.1.intermediate.dense.weight_orig', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'bert.encoder.layer.0.attention.output.dense.weight_orig', 'bert.encoder.layer.0.attention.output.dense.weight_mask', 'bert.encoder.layer.1.output.dense.weight_orig', 'bert.encoder.layer.0.intermediate.dense.weight_mask', 'bert.encoder.layer.0.attention.self.value.weight_mask', 'bert.encoder.layer.1.attention.self.value.weight_orig', 'bert.encoder.layer.0.attention.self.key.weight_mask', 'bert.encoder.layer.0.output.dense.weight_mask', 'bert.encoder.layer.1.attention.self.value.weight_mask', 'bert.encoder.layer.1.attention.self.key.weight_mask', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.weight_orig', 'bert.encoder.layer.1.attention.self.query.weight_orig', 'bert.encoder.layer.0.attention.self.value.weight_orig', 'bert.encoder.layer.1.attention.self.key.weight_orig', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.0.attention.self.query.weight_mask', 'bert.encoder.layer.1.attention.output.dense.weight_orig', 'cls.predictions.decoder.weight', 'bert.encoder.layer.1.output.dense.weight_mask', 'bert.encoder.layer.0.attention.self.key.weight_orig', 'bert.encoder.layer.0.attention.self.query.weight_orig']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/abdullah/Code/dl/lt_bert/best_models/pruned_best_tiny_bert and are newly initialized: ['bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.output.dense.weight', 'classifier.weight', 'classifier.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "train_df = tsv_to_df(TRAIN_FILE_LOC)\n",
    "test_df = tsv_to_df(TEST_FILE_LOC)\n",
    "eval_df = tsv_to_df(EVAL_FILE_LOC)\n",
    "\n",
    "\n",
    "class TINYDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(value[idx])\n",
    "                for key, value in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_encodings = tokenizer(train_df['text'].tolist(\n",
    "), padding=True, truncation=True, max_length=512)\n",
    "test_encodings = tokenizer(test_df['text'].tolist(\n",
    "), padding=True, truncation=True, max_length=512)\n",
    "eval_encodings = tokenizer(eval_df['text'].tolist(\n",
    "), padding=True, truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = TINYDataset(train_encodings, train_df['class'].tolist())\n",
    "test_dataset = TINYDataset(test_encodings, test_df['class'].tolist())\n",
    "eval_dataset = TINYDataset(eval_encodings, eval_df['class'].tolist())\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to('cuda')\n",
    "model.manual_seed = 14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Epoch Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "***** Running training *****\n",
      "  Num examples = 697\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n",
      "100%|██████████| 15/15 [00:00<00:00, 33.87it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.099, 'learning_rate': 1.5e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|██████████| 15/15 [00:00<00:00, 33.87it/s]Saving model checkpoint to temp/checkpoint-15\n",
      "Configuration saved in temp/checkpoint-15/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0983589887619019, 'eval_runtime': 0.0171, 'eval_samples_per_second': 5743.214, 'eval_steps_per_second': 117.208, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-15/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-15 (score: 1.0983589887619019).\n",
      "100%|██████████| 15/15 [00:01<00:00,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1.7031, 'train_samples_per_second': 409.253, 'train_steps_per_second': 8.807, 'train_loss': 1.0989625295003256, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=1.0989625295003256, metrics={'train_runtime': 1.7031, 'train_samples_per_second': 409.253, 'train_steps_per_second': 8.807, 'train_loss': 1.0989625295003256, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"temp\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=96,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    overwrite_output_dir=True,\n",
    "    logging_dir=f\"temp/logs\",\n",
    "    logging_steps=15,\n",
    "    save_steps=15,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    seed=14,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 Epoch with 1 epoch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/abdullah/Code/dl/lt_bert/best_models/1/1_sail_sentiment_50/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/abdullah/Code/dl/lt_bert/best_models/pruned_best_tiny_bert\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/abdullah/Code/dl/lt_bert/best_models/1/1_sail_sentiment_50/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/abdullah/Code/dl/lt_bert/best_models/1/1_sail_sentiment_50.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "***** Running training *****\n",
      "  Num examples = 697\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1500\n",
      "  7%|▋         | 100/1500 [00:01<00:19, 71.66it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0976, 'learning_rate': 1e-05, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  7%|▋         | 100/1500 [00:01<00:19, 71.66it/s]Saving model checkpoint to temp/checkpoint-100\n",
      "Configuration saved in temp/checkpoint-100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0944733619689941, 'eval_f1': 0.1973804447151995, 'eval_runtime': 0.0154, 'eval_samples_per_second': 6367.213, 'eval_steps_per_second': 129.943, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-100/pytorch_model.bin\n",
      " 13%|█▎        | 200/1500 [00:03<00:17, 75.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0932, 'learning_rate': 2e-05, 'epoch': 13.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 13%|█▎        | 200/1500 [00:03<00:17, 75.65it/s]Saving model checkpoint to temp/checkpoint-200\n",
      "Configuration saved in temp/checkpoint-200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.091084361076355, 'eval_f1': 0.1973804447151995, 'eval_runtime': 0.0176, 'eval_samples_per_second': 5552.593, 'eval_steps_per_second': 113.318, 'epoch': 13.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-200/pytorch_model.bin\n",
      " 20%|██        | 300/1500 [00:05<00:16, 71.81it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0908, 'learning_rate': 3e-05, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 300/1500 [00:05<00:16, 71.81it/s]Saving model checkpoint to temp/checkpoint-300\n",
      "Configuration saved in temp/checkpoint-300/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0905683040618896, 'eval_f1': 0.1973804447151995, 'eval_runtime': 0.018, 'eval_samples_per_second': 5434.473, 'eval_steps_per_second': 110.908, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-300/pytorch_model.bin\n",
      " 27%|██▋       | 400/1500 [00:08<00:15, 69.25it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0916, 'learning_rate': 4e-05, 'epoch': 26.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 27%|██▋       | 400/1500 [00:08<00:15, 69.25it/s]Saving model checkpoint to temp/checkpoint-400\n",
      "Configuration saved in temp/checkpoint-400/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0902270078659058, 'eval_f1': 0.1973804447151995, 'eval_runtime': 0.014, 'eval_samples_per_second': 6976.506, 'eval_steps_per_second': 142.378, 'epoch': 26.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-400/pytorch_model.bin\n",
      " 33%|███▎      | 500/1500 [00:10<00:13, 74.62it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0905, 'learning_rate': 5e-05, 'epoch': 33.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 33%|███▎      | 500/1500 [00:10<00:13, 74.62it/s]Saving model checkpoint to temp/checkpoint-500\n",
      "Configuration saved in temp/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0892739295959473, 'eval_f1': 0.1973804447151995, 'eval_runtime': 0.0171, 'eval_samples_per_second': 5737.362, 'eval_steps_per_second': 117.089, 'epoch': 33.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-500/pytorch_model.bin\n",
      " 40%|████      | 600/1500 [00:12<00:12, 72.66it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0865, 'learning_rate': 4.5e-05, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 40%|████      | 600/1500 [00:12<00:12, 72.66it/s]Saving model checkpoint to temp/checkpoint-600\n",
      "Configuration saved in temp/checkpoint-600/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0827983617782593, 'eval_f1': 0.37032616618075803, 'eval_runtime': 0.0174, 'eval_samples_per_second': 5621.238, 'eval_steps_per_second': 114.719, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-600/pytorch_model.bin\n",
      " 47%|████▋     | 700/1500 [00:14<00:10, 75.85it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0236, 'learning_rate': 4e-05, 'epoch': 46.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 47%|████▋     | 700/1500 [00:14<00:10, 75.85it/s]Saving model checkpoint to temp/checkpoint-700\n",
      "Configuration saved in temp/checkpoint-700/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1270883083343506, 'eval_f1': 0.3337198515769944, 'eval_runtime': 0.0153, 'eval_samples_per_second': 6416.913, 'eval_steps_per_second': 130.957, 'epoch': 46.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-700/pytorch_model.bin\n",
      " 53%|█████▎    | 800/1500 [00:16<00:09, 76.86it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8628, 'learning_rate': 3.5e-05, 'epoch': 53.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 53%|█████▎    | 800/1500 [00:16<00:09, 76.86it/s]Saving model checkpoint to temp/checkpoint-800\n",
      "Configuration saved in temp/checkpoint-800/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.227048397064209, 'eval_f1': 0.3660187334696188, 'eval_runtime': 0.016, 'eval_samples_per_second': 6125.261, 'eval_steps_per_second': 125.005, 'epoch': 53.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-800/pytorch_model.bin\n",
      " 60%|██████    | 900/1500 [00:19<00:07, 75.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7635, 'learning_rate': 3e-05, 'epoch': 60.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 60%|██████    | 900/1500 [00:19<00:07, 75.64it/s]Saving model checkpoint to temp/checkpoint-900\n",
      "Configuration saved in temp/checkpoint-900/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2936452627182007, 'eval_f1': 0.3845804988662131, 'eval_runtime': 0.0156, 'eval_samples_per_second': 6275.735, 'eval_steps_per_second': 128.076, 'epoch': 60.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-900/pytorch_model.bin\n",
      " 67%|██████▋   | 1000/1500 [00:21<00:06, 75.80it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.72, 'learning_rate': 2.5e-05, 'epoch': 66.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|██████▋   | 1000/1500 [00:21<00:06, 75.80it/s]Saving model checkpoint to temp/checkpoint-1000\n",
      "Configuration saved in temp/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3415125608444214, 'eval_f1': 0.3548979591836735, 'eval_runtime': 0.0179, 'eval_samples_per_second': 5478.731, 'eval_steps_per_second': 111.811, 'epoch': 66.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1000/pytorch_model.bin\n",
      " 73%|███████▎  | 1100/1500 [00:23<00:05, 76.47it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6807, 'learning_rate': 2e-05, 'epoch': 73.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 73%|███████▎  | 1100/1500 [00:23<00:05, 76.47it/s]Saving model checkpoint to temp/checkpoint-1100\n",
      "Configuration saved in temp/checkpoint-1100/config.json\n",
      "Model weights saved in temp/checkpoint-1100/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3823120594024658, 'eval_f1': 0.3780133292896717, 'eval_runtime': 0.0148, 'eval_samples_per_second': 6623.51, 'eval_steps_per_second': 135.174, 'epoch': 73.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1200/1500 [00:25<00:03, 77.12it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6538, 'learning_rate': 1.5e-05, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|████████  | 1200/1500 [00:25<00:03, 77.12it/s]Saving model checkpoint to temp/checkpoint-1200\n",
      "Configuration saved in temp/checkpoint-1200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4156309366226196, 'eval_f1': 0.39971313200604924, 'eval_runtime': 0.0171, 'eval_samples_per_second': 5747.47, 'eval_steps_per_second': 117.295, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1200/pytorch_model.bin\n",
      " 87%|████████▋ | 1300/1500 [00:27<00:02, 76.07it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6506, 'learning_rate': 1e-05, 'epoch': 86.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 87%|████████▋ | 1300/1500 [00:27<00:02, 76.07it/s]Saving model checkpoint to temp/checkpoint-1300\n",
      "Configuration saved in temp/checkpoint-1300/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4331254959106445, 'eval_f1': 0.4178302900107411, 'eval_runtime': 0.017, 'eval_samples_per_second': 5757.21, 'eval_steps_per_second': 117.494, 'epoch': 86.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1300/pytorch_model.bin\n",
      " 93%|█████████▎| 1400/1500 [00:29<00:01, 77.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6408, 'learning_rate': 5e-06, 'epoch': 93.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 93%|█████████▎| 1400/1500 [00:29<00:01, 77.65it/s]Saving model checkpoint to temp/checkpoint-1400\n",
      "Configuration saved in temp/checkpoint-1400/config.json\n",
      "Model weights saved in temp/checkpoint-1400/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4417887926101685, 'eval_f1': 0.4008878876225815, 'eval_runtime': 0.0143, 'eval_samples_per_second': 6865.228, 'eval_steps_per_second': 140.107, 'epoch': 93.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:32<00:00, 72.44it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6376, 'learning_rate': 0.0, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 1500/1500 [00:32<00:00, 72.44it/s]Saving model checkpoint to temp/checkpoint-1500\n",
      "Configuration saved in temp/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.447922706604004, 'eval_f1': 0.4008878876225815, 'eval_runtime': 0.0144, 'eval_samples_per_second': 6789.366, 'eval_steps_per_second': 138.558, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1500/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-600 (score: 1.0827983617782593).\n",
      "100%|██████████| 1500/1500 [00:32<00:00, 45.80it/s]\n",
      "***** Running training *****\n",
      "  Num examples = 697\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 48\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 32.7551, 'train_samples_per_second': 2127.914, 'train_steps_per_second': 45.794, 'train_loss': 0.8789064636230469, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 100/1500 [00:01<00:17, 77.81it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.076, 'learning_rate': 1e-05, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|▋         | 100/1500 [00:01<00:17, 77.81it/s]Saving model checkpoint to temp/checkpoint-100\n",
      "Configuration saved in temp/checkpoint-100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0815467834472656, 'eval_accuracy': 0.4489795918367347, 'eval_runtime': 0.0152, 'eval_samples_per_second': 6449.333, 'eval_steps_per_second': 131.619, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-100/pytorch_model.bin\n",
      " 13%|█▎        | 200/1500 [00:03<00:17, 74.79it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0707, 'learning_rate': 2e-05, 'epoch': 13.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|█▎        | 200/1500 [00:03<00:17, 74.79it/s]Saving model checkpoint to temp/checkpoint-200\n",
      "Configuration saved in temp/checkpoint-200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0770145654678345, 'eval_accuracy': 0.41836734693877553, 'eval_runtime': 0.0166, 'eval_samples_per_second': 5892.481, 'eval_steps_per_second': 120.255, 'epoch': 13.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-200/pytorch_model.bin\n",
      " 20%|██        | 300/1500 [00:05<00:15, 76.47it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0462, 'learning_rate': 3e-05, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 300/1500 [00:05<00:15, 76.47it/s]Saving model checkpoint to temp/checkpoint-300\n",
      "Configuration saved in temp/checkpoint-300/config.json\n",
      "Model weights saved in temp/checkpoint-300/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0742554664611816, 'eval_accuracy': 0.4489795918367347, 'eval_runtime': 0.0156, 'eval_samples_per_second': 6282.353, 'eval_steps_per_second': 128.211, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 400/1500 [00:07<00:14, 74.29it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9686, 'learning_rate': 4e-05, 'epoch': 26.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 400/1500 [00:07<00:14, 74.29it/s]Saving model checkpoint to temp/checkpoint-400\n",
      "Configuration saved in temp/checkpoint-400/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1234623193740845, 'eval_accuracy': 0.3673469387755102, 'eval_runtime': 0.0144, 'eval_samples_per_second': 6805.553, 'eval_steps_per_second': 138.889, 'epoch': 26.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-400/pytorch_model.bin\n",
      " 33%|███▎      | 500/1500 [00:10<00:13, 72.38it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8617, 'learning_rate': 5e-05, 'epoch': 33.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 500/1500 [00:10<00:13, 72.38it/s]Saving model checkpoint to temp/checkpoint-500\n",
      "Configuration saved in temp/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2079501152038574, 'eval_accuracy': 0.4489795918367347, 'eval_runtime': 0.0148, 'eval_samples_per_second': 6638.701, 'eval_steps_per_second': 135.484, 'epoch': 33.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-500/pytorch_model.bin\n",
      " 40%|████      | 600/1500 [00:12<00:11, 75.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7642, 'learning_rate': 4.5e-05, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 600/1500 [00:12<00:11, 75.54it/s]Saving model checkpoint to temp/checkpoint-600\n",
      "Configuration saved in temp/checkpoint-600/config.json\n",
      "Model weights saved in temp/checkpoint-600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.284836769104004, 'eval_accuracy': 0.4387755102040816, 'eval_runtime': 0.0128, 'eval_samples_per_second': 7682.593, 'eval_steps_per_second': 156.788, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 700/1500 [00:14<00:10, 75.86it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7059, 'learning_rate': 4e-05, 'epoch': 46.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 700/1500 [00:14<00:10, 75.86it/s]Saving model checkpoint to temp/checkpoint-700\n",
      "Configuration saved in temp/checkpoint-700/config.json\n",
      "Model weights saved in temp/checkpoint-700/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3347644805908203, 'eval_accuracy': 0.45918367346938777, 'eval_runtime': 0.0147, 'eval_samples_per_second': 6644.925, 'eval_steps_per_second': 135.611, 'epoch': 46.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 800/1500 [00:16<00:09, 72.67it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6544, 'learning_rate': 3.5e-05, 'epoch': 53.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 800/1500 [00:16<00:09, 72.67it/s]Saving model checkpoint to temp/checkpoint-800\n",
      "Configuration saved in temp/checkpoint-800/config.json\n",
      "Model weights saved in temp/checkpoint-800/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.425398349761963, 'eval_accuracy': 0.47959183673469385, 'eval_runtime': 0.0142, 'eval_samples_per_second': 6912.099, 'eval_steps_per_second': 141.063, 'epoch': 53.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 900/1500 [00:18<00:08, 71.78it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6276, 'learning_rate': 3e-05, 'epoch': 60.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 900/1500 [00:18<00:08, 71.78it/s]Saving model checkpoint to temp/checkpoint-900\n",
      "Configuration saved in temp/checkpoint-900/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4655227661132812, 'eval_accuracy': 0.5, 'eval_runtime': 0.0129, 'eval_samples_per_second': 7575.55, 'eval_steps_per_second': 154.603, 'epoch': 60.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-900/pytorch_model.bin\n",
      " 67%|██████▋   | 1000/1500 [00:20<00:06, 75.70it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6, 'learning_rate': 2.5e-05, 'epoch': 66.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 1000/1500 [00:20<00:06, 75.70it/s]Saving model checkpoint to temp/checkpoint-1000\n",
      "Configuration saved in temp/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.512174367904663, 'eval_accuracy': 0.47959183673469385, 'eval_runtime': 0.018, 'eval_samples_per_second': 5440.659, 'eval_steps_per_second': 111.034, 'epoch': 66.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1000/pytorch_model.bin\n",
      " 73%|███████▎  | 1100/1500 [00:22<00:05, 75.45it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5728, 'learning_rate': 2e-05, 'epoch': 73.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 73%|███████▎  | 1100/1500 [00:22<00:05, 75.45it/s]Saving model checkpoint to temp/checkpoint-1100\n",
      "Configuration saved in temp/checkpoint-1100/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5403228998184204, 'eval_accuracy': 0.46938775510204084, 'eval_runtime': 0.0162, 'eval_samples_per_second': 6050.694, 'eval_steps_per_second': 123.484, 'epoch': 73.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1100/pytorch_model.bin\n",
      " 80%|████████  | 1200/1500 [00:24<00:03, 76.13it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5525, 'learning_rate': 1.5e-05, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 1200/1500 [00:24<00:03, 76.13it/s]Saving model checkpoint to temp/checkpoint-1200\n",
      "Configuration saved in temp/checkpoint-1200/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.58753502368927, 'eval_accuracy': 0.46938775510204084, 'eval_runtime': 0.0136, 'eval_samples_per_second': 7224.822, 'eval_steps_per_second': 147.445, 'epoch': 80.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1200/pytorch_model.bin\n",
      " 87%|████████▋ | 1300/1500 [00:26<00:02, 76.43it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5459, 'learning_rate': 1e-05, 'epoch': 86.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 87%|████████▋ | 1300/1500 [00:26<00:02, 76.43it/s]Saving model checkpoint to temp/checkpoint-1300\n",
      "Configuration saved in temp/checkpoint-1300/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6077765226364136, 'eval_accuracy': 0.46938775510204084, 'eval_runtime': 0.0151, 'eval_samples_per_second': 6478.711, 'eval_steps_per_second': 132.219, 'epoch': 86.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1300/pytorch_model.bin\n",
      " 93%|█████████▎| 1400/1500 [00:28<00:01, 75.59it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.526, 'learning_rate': 5e-06, 'epoch': 93.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 93%|█████████▎| 1400/1500 [00:28<00:01, 75.59it/s]Saving model checkpoint to temp/checkpoint-1400\n",
      "Configuration saved in temp/checkpoint-1400/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6077141761779785, 'eval_accuracy': 0.47959183673469385, 'eval_runtime': 0.014, 'eval_samples_per_second': 7024.674, 'eval_steps_per_second': 143.361, 'epoch': 93.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1400/pytorch_model.bin\n",
      "100%|██████████| 1500/1500 [00:30<00:00, 75.02it/s]***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5256, 'learning_rate': 0.0, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1500/1500 [00:30<00:00, 75.02it/s]Saving model checkpoint to temp/checkpoint-1500\n",
      "Configuration saved in temp/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6162593364715576, 'eval_accuracy': 0.47959183673469385, 'eval_runtime': 0.0139, 'eval_samples_per_second': 7033.208, 'eval_steps_per_second': 143.535, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in temp/checkpoint-1500/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-300 (score: 1.0742554664611816).\n",
      "100%|██████████| 1500/1500 [00:31<00:00, 47.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 31.5273, 'train_samples_per_second': 2210.785, 'train_steps_per_second': 47.578, 'train_loss': 0.7398870595296224, 'epoch': 100.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.7398870595296224, metrics={'train_runtime': 31.5273, 'train_samples_per_second': 2210.785, 'train_steps_per_second': 47.578, 'train_loss': 0.7398870595296224, 'epoch': 100.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = '/home/abdullah/Code/dl/lt_bert/best_models/1/1_sail_sentiment_50'\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=3).to('cuda')\n",
    "model.manual_seed = 14\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'bert.encoder.layer.0' in name:\n",
    "        # print(name, param.requires_grad)\n",
    "        param.requires_grad = False\n",
    "# print(\"\\n\\n\\n\")\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param.requires_grad)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"temp\",\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=96,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    overwrite_output_dir=True,\n",
    "    logging_dir=f\"temp/logs\",\n",
    "    logging_steps=100,\n",
    "    save_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    seed=14,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=f1_calculator,\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# print(cool.metrics)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30945d60abeb4d30e097bab3ad7b6ead7c1fba264acb4ede644ab6174c0ba9cb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_499A': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
